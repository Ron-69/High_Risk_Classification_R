# High_Risk_Classification_R
Este projeto demonstra o uso de t√©cnicas Classifica√ß√£o Bin√°ria (Regress√£o Log√≠stica/SVM) , com o objetivo de Classificar um cliente como sendo de "Alto Custo" (Top 25% dos valores de charges) ou "Custo Normal" (Bottom 75%).

# üö® 02_High_Risk_Classification: Identifica√ß√£o de Clientes de Alto Risco (Regress√£o Log√≠stica)

## üéØ Objetivo do Projeto

Este projeto implementa uma solu√ß√£o de **Classifica√ß√£o Bin√°ria** usando **Regress√£o Log√≠stica** em R para identificar clientes de seguro sa√∫de que representam **Alto Risco de Custo**.

O objetivo √© prever se o custo anual de um cliente estar√° no **Top 25%** do dataset. A avalia√ß√£o do modelo √© focada em **Recall** e **AUC**, m√©tricas essenciais para lidar com o desbalanceamento de classes e garantir a captura m√°xima de clientes de alto risco real.

## üîë Metodologia e Decis√µes Estrat√©gicas

| Aspecto | Detalhe da Implementa√ß√£o |
| :--- | :--- |
| **Vari√°vel Alvo ($Y$)** | `high_cost`: Criada usando o 75¬∫ Percentil (Q3: R$ 16.639,91) do custo (`charges`). |
| **Desbalanceamento** | Dataset desbalanceado: **1003 Normal** vs. **335 Alto Risco** (25%). |
| **Particionamento** | **Estratificado** (`caret::createDataPartition`) para manter a propor√ß√£o da classe `Alto_Risco` nos conjuntos de Treino e Teste. |
| **T√©cnica** | **Regress√£o Log√≠stica (GLM, family=binomial)**: Utilizada para modelar a probabilidade do evento de Alto Risco. |
| **Pr√©-processamento** | Vari√°veis num√©ricas padronizadas (`center` e `scale`) para otimizar o treinamento do modelo. |

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** R
* **Pacotes Principais:** `caret`, `dplyr`, `pROC`, `readr`

---

## üìä Fluxo de Trabalho e Resultados Consolidados

### C√©lula 1 & 2: Setup e Engenharia da Vari√°vel Alvo

A vari√°vel alvo `high_cost` foi criada e confirmou o desbalanceamento.

#### C√≥digo R (Essencial)

```R
# --- C√âLULA 1 & 2: SETUP E FEATURE ENGINEERING ---
# Carrega dados, calcula o 75¬∫ percentil (Q3) e cria a vari√°vel high_cost
q3_charges <- quantile(insurance_data$charges, 0.75)
insurance_data <- insurance_data %>%
  mutate(high_cost = ifelse(charges > q3_charges, "Alto_Risco", "Normal")) 
# ... c√≥digo continua ...
```

## Sa√≠da Obtida

O Limiar de Alto Custo (Q3) √©: 16639.91 
Balanceamento da Classe 'high_cost':
    Normal Alto_Risco 
      1003        335

### C√©lula 3: Pr√©-processamentoDivis√£o 70/30 (estratificada) e aplica√ß√£o da padroniza√ß√£o (center e scale).

C√≥digo R (Essencial)

R# --- C√âLULA 3: PR√â-PROCESSAMENTO E PARTICIONAMENTO ---

# C√≥digo para createDataPartition e preProcess

## Sa√≠da Obtida

Dimens√µes do Set de Treino Processado: 938 7
C√©lula 4: Treinamento da Regress√£o Log√≠stica
O modelo foi treinado no conjunto processado.

C√≥digo R (Essencial)

R# --- C√âLULA 4: TREINAMENTO DA REGRESS√ÉO LOG√çSTICA ---

# logreg_model <- glm(high_cost ~ ..., family = "binomial", ...)

## Sa√≠da e An√°lise de Coeficientes

O summary demonstra que o H√°bito de Fumar √© o preditor mais forte.Sum√°rio do Modelo de Regress√£o Log√≠stica:

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
(Intercept)      -2.56700   0.30082  -8.533 < 2e-16 ***
age               0.47801   0.14208   3.364 0.000767 ***
sexmale          -0.11175   0.26304  -0.425 0.670941    
bmi               0.31932   0.13674   2.335 0.019531 * children          0.13752   0.12432   1.106 0.268658    
smokeryes         5.78865   0.39074  14.815 < 2e-16 ***
regionnorthwest  -0.01247   0.37653  -0.033 0.973588    
regionsoutheast   0.10613   0.36625   0.290 0.771996    
regionsouthwest  -0.45854   0.38851  -1.180 0.237903    
---

## Conclus√£o da Signific√¢ncia

As vari√°veis **`smokeryes`**, **`age`** e **`bmi`** s√£o estatisticamente significativas ($P$-Value baixo) na previs√£o do Alto Risco. O coeficiente de $\mathbf{5.79}$ para `smokeryes` indica um aumento exponencial na probabilidade de ser classificado como Alto Risco.

---

### C√©lula 5: Avalia√ß√£o Focada em Recall e AUC

A avalia√ß√£o no Set de Teste (30%) confirma a robustez do modelo para identificar a classe positiva (`Alto_Risco`).

#### Matriz de Confus√£o e M√©tricas ($Threshold \ P=0.5$)

O resultado da Matriz de Confus√£o no Set de Teste √© o seguinte:
## Confusion Matrix and Statistics

             Reference
Prediction    Normal Alto_Risco
  Normal         291         25
  Alto_Risco       9         75

Recall (Sensibilidade): 0.75 
√Årea Sob a Curva ROC (AUC): 0.8669 
#### An√°lise das M√©tricas Chave

| M√©trica | Valor | Objetivo Estrat√©gico |
| :--- | :--- | :--- |
| **Recall (Sensibilidade)** | $\mathbf{0.7500}$ | **Sucesso:** O modelo capturou 75% dos clientes que realmente s√£o de alto risco (Minimiza√ß√£o de Falsos Negativos). |
| **AUC** | $\mathbf{0.8669}$ | **Forte Desempenho:** Indica que o modelo tem um excelente poder de discrimina√ß√£o entre as classes. |
| **Especificidade** | $0.9700$ | $97\%$ dos clientes normais foram corretamente identificados. |

---

### Curva ROC e AUC üìà

A √Årea Sob a Curva (AUC) √© de **0.8669**, um valor forte que confirma o excelente poder discriminat√≥rio do modelo, independentemente do *threshold* de classifica√ß√£o escolhido.

O gr√°fico a seguir ilustra o *trade-off* entre a Taxa de Verdadeiros Positivos (Recall) e a Taxa de Falsos Positivos em todos os *thresholds* poss√≠veis:

![Curva ROC para Identifica√ß√£o de Alto Risco](./assets/Curve_ROC_High_Risk_Identifier.png)
**Nota sobre a Curva ROC:** A **Curva ROC** valida o forte desempenho do modelo, pois a √°rea sob a curva (AUC) est√° bem pr√≥xima de 1.0, confirmando a robustez da classifica√ß√£o.

## üìà Conclus√£o e Pr√≥ximos Passos

O projeto alcan√ßou o objetivo de construir um modelo de classifica√ß√£o de Alto Risco com alta performance:
O modelo identificou $\mathbf{75\%}$ dos clientes de Alto Risco (Recall), minimizando o risco financeiro de Falsos Negativos.
O AUC de $\mathbf{0.8669}$ confirma que o modelo √© altamente eficaz e generaliz√°vel.
A An√°lise de Coeficientes identificou Fumar como o fator de risco mais cr√≠tico.
Para otimizar o modelo em um ambiente de produ√ß√£o (minimizar os 25 Falsos Negativos restantes), os pr√≥ximos passos envolveriam: ajustar o threshold de classifica√ß√£o para um valor menor que $0.5$ (priorizando o Recall sobre a Especificidade) ou aplicar t√©cnicas avan√ßadas de Balanceamento de Classes (como SMOTE) no conjunto de treino.